{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd #data processing(reading csv file)# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n '''       \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:25.491554Z","iopub.execute_input":"2023-01-17T18:00:25.492201Z","iopub.status.idle":"2023-01-17T18:00:25.503155Z","shell.execute_reply.started":"2023-01-17T18:00:25.492158Z","shell.execute_reply":"2023-01-17T18:00:25.502092Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n \""},"metadata":{}}]},{"cell_type":"code","source":"train_classes = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:25.505660Z","iopub.execute_input":"2023-01-17T18:00:25.506085Z","iopub.status.idle":"2023-01-17T18:00:25.592683Z","shell.execute_reply.started":"2023-01-17T18:00:25.506052Z","shell.execute_reply":"2023-01-17T18:00:25.590862Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#define a function to split the tags and store a set of the tags in a variable called labels.\n#set is used to return the unique labels in the tags\nlabels = set()\ndef splitting_tags(tags):\n    for tag in tags.split():\n        labels.add(tag)\n\n#we redefine the train_classes by creating a copy of it so as not to overwrite the existing one. \n#so a copy of the train classes is stored in the variable train_classes1, we convert labels which is a set to a list.\ntrain_classes1 = train_classes.copy()\ntrain_classes1['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:25.595959Z","iopub.execute_input":"2023-01-17T18:00:25.596342Z","iopub.status.idle":"2023-01-17T18:00:25.652083Z","shell.execute_reply.started":"2023-01-17T18:00:25.596311Z","shell.execute_reply":"2023-01-17T18:00:25.650757Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['agriculture', 'bare_ground', 'haze', 'habitation', 'conventional_mine', 'cultivation', 'water', 'cloudy', 'slash_burn', 'artisinal_mine', 'primary', 'selective_logging', 'blow_down', 'partly_cloudy', 'clear', 'road', 'blooming']\n","output_type":"stream"}]},{"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes\nfor tag in labels:\n    train_classes1[tag] = train_classes1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n## adding .jpg extension to the column image_name so as to have same name format as the image files\ntrain_classes1['image_name'] = train_classes1['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntrain_classes1.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:25.653814Z","iopub.execute_input":"2023-01-17T18:00:25.654324Z","iopub.status.idle":"2023-01-17T18:00:26.318822Z","shell.execute_reply.started":"2023-01-17T18:00:25.654281Z","shell.execute_reply":"2023-01-17T18:00:26.317661Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"    image_name                                       tags  agriculture  \\\n0  train_0.jpg                               haze primary            0   \n1  train_1.jpg            agriculture clear primary water            1   \n2  train_2.jpg                              clear primary            0   \n3  train_3.jpg                              clear primary            0   \n4  train_4.jpg  agriculture clear habitation primary road            1   \n\n   bare_ground  haze  habitation  conventional_mine  cultivation  water  \\\n0            0     1           0                  0            0      0   \n1            0     0           0                  0            0      1   \n2            0     0           0                  0            0      0   \n3            0     0           0                  0            0      0   \n4            0     0           1                  0            0      0   \n\n   cloudy  slash_burn  artisinal_mine  primary  selective_logging  blow_down  \\\n0       0           0               0        1                  0          0   \n1       0           0               0        1                  0          0   \n2       0           0               0        1                  0          0   \n3       0           0               0        1                  0          0   \n4       0           0               0        1                  0          0   \n\n   partly_cloudy  clear  road  blooming  \n0              0      0     0         0  \n1              0      1     0         0  \n2              0      1     0         0  \n3              0      1     0         0  \n4              0      1     1         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n      <th>agriculture</th>\n      <th>bare_ground</th>\n      <th>haze</th>\n      <th>habitation</th>\n      <th>conventional_mine</th>\n      <th>cultivation</th>\n      <th>water</th>\n      <th>cloudy</th>\n      <th>slash_burn</th>\n      <th>artisinal_mine</th>\n      <th>primary</th>\n      <th>selective_logging</th>\n      <th>blow_down</th>\n      <th>partly_cloudy</th>\n      <th>clear</th>\n      <th>road</th>\n      <th>blooming</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0.jpg</td>\n      <td>haze primary</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1.jpg</td>\n      <td>agriculture clear primary water</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2.jpg</td>\n      <td>clear primary</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3.jpg</td>\n      <td>clear primary</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4.jpg</td>\n      <td>agriculture clear habitation primary road</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#importing tensorflow libraries for training the dataset\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:26.326079Z","iopub.execute_input":"2023-01-17T18:00:26.329354Z","iopub.status.idle":"2023-01-17T18:00:33.175234Z","shell.execute_reply.started":"2023-01-17T18:00:26.329295Z","shell.execute_reply":"2023-01-17T18:00:33.174251Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#defining the columns, that is the labels that were newly added to the train_classes via hot encoding.\ncolumns = list(train_classes1.columns[2:]) #from index 2 to the end d","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:33.178630Z","iopub.execute_input":"2023-01-17T18:00:33.180740Z","iopub.status.idle":"2023-01-17T18:00:33.185022Z","shell.execute_reply.started":"2023-01-17T18:00:33.180708Z","shell.execute_reply":"2023-01-17T18:00:33.184038Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"columns","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:33.186606Z","iopub.execute_input":"2023-01-17T18:00:33.187410Z","iopub.status.idle":"2023-01-17T18:00:33.206547Z","shell.execute_reply.started":"2023-01-17T18:00:33.187343Z","shell.execute_reply":"2023-01-17T18:00:33.205032Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['agriculture',\n 'bare_ground',\n 'haze',\n 'habitation',\n 'conventional_mine',\n 'cultivation',\n 'water',\n 'cloudy',\n 'slash_burn',\n 'artisinal_mine',\n 'primary',\n 'selective_logging',\n 'blow_down',\n 'partly_cloudy',\n 'clear',\n 'road',\n 'blooming']"},"metadata":{}}]},{"cell_type":"code","source":"#define a function for fbeta scoring\ndef fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n    \n    beta_squared = beta**2\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n    return fb","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:33.208944Z","iopub.execute_input":"2023-01-17T18:00:33.209944Z","iopub.status.idle":"2023-01-17T18:00:33.217805Z","shell.execute_reply.started":"2023-01-17T18:00:33.209908Z","shell.execute_reply":"2023-01-17T18:00:33.216673Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#define a function for accuracy for multi_label classification\ndef multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n        \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n                       axis = 1)\n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:00:33.220427Z","iopub.execute_input":"2023-01-17T18:00:33.220737Z","iopub.status.idle":"2023-01-17T18:00:33.231475Z","shell.execute_reply.started":"2023-01-17T18:00:33.220711Z","shell.execute_reply":"2023-01-17T18:00:33.230250Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n#defining our model using a function build_model()\ndef build_model():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n\n    opt = Adam(lr=1e-4)\n\n    model.compile(loss='binary_crossentropy',\n              # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n              optimizer=opt,\n              metrics=[multi_label_acc, fbeta])\n\n    return model","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:01:01.241871Z","iopub.execute_input":"2023-01-17T18:01:01.243196Z","iopub.status.idle":"2023-01-17T18:01:01.256729Z","shell.execute_reply.started":"2023-01-17T18:01:01.243134Z","shell.execute_reply":"2023-01-17T18:01:01.255491Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\nsave_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', monitor = 'val_fbeta', mode = 'max',\n                                       save_best_only = True, save_weights_only = True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:01:01.639340Z","iopub.execute_input":"2023-01-17T18:01:01.639739Z","iopub.status.idle":"2023-01-17T18:01:01.645129Z","shell.execute_reply.started":"2023-01-17T18:01:01.639704Z","shell.execute_reply":"2023-01-17T18:01:01.644075Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#initializing imagedatagenerator with a validation split of 0.2\ntrain_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n\n#generating train data generator which is 80% of the train dataset\n#note that a generator contains both features and target of the data\ntrain_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))\n\n#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\nval_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:01:42.719672Z","iopub.execute_input":"2023-01-17T18:01:42.720192Z","iopub.status.idle":"2023-01-17T18:02:33.535711Z","shell.execute_reply.started":"2023-01-17T18:01:42.720152Z","shell.execute_reply":"2023-01-17T18:02:33.534530Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 32384 validated image filenames.\nFound 8095 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#setting up step size for training and validation image data\nstep_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\nstep_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:02:33.537815Z","iopub.execute_input":"2023-01-17T18:02:33.538458Z","iopub.status.idle":"2023-01-17T18:02:33.544111Z","shell.execute_reply.started":"2023-01-17T18:02:33.538418Z","shell.execute_reply":"2023-01-17T18:02:33.543140Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#initializing the model\nmodelnew = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:02:33.546076Z","iopub.execute_input":"2023-01-17T18:02:33.546488Z","iopub.status.idle":"2023-01-17T18:02:37.706401Z","shell.execute_reply.started":"2023-01-17T18:02:33.546454Z","shell.execute_reply":"2023-01-17T18:02:37.705100Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2023-01-17 18:02:33.691238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.692196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.808529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.809317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.810074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.810796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:33.813432: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-17 18:02:34.076202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:34.077026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:34.077743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:34.078465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:34.079177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:34.079884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.846545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.847772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.848961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.850227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.851063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.851828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-01-17 18:02:36.854884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 18:02:36.855687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#this shows the summary of the model, simply put as the model architecture\nmodelnew.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:02:37.711549Z","iopub.execute_input":"2023-01-17T18:02:37.712046Z","iopub.status.idle":"2023-01-17T18:02:37.726946Z","shell.execute_reply.started":"2023-01-17T18:02:37.712005Z","shell.execute_reply":"2023-01-17T18:02:37.725682Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization (BatchNo (None, 128, 128, 3)       12        \n_________________________________________________________________\nconv2d (Conv2D)              (None, 128, 128, 32)      896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 126, 126, 32)      9248      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 63, 63, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 63, 63, 64)        18496     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 61, 61, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 30, 30, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 30, 30, 128)       73856     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 28, 28, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 14, 14, 256)       295168    \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 12, 12, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               4719104   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 17)                8721      \n=================================================================\nTotal params: 5,900,093\nTrainable params: 5,900,087\nNon-trainable params: 6\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#fitting our model using the parameters already defined \nmodelnew.fit(x = train_generator, steps_per_epoch = step_train_size, validation_data = val_generator, \n           validation_steps = step_val_size,epochs = 1, \n           callbacks = [save_best_check_point])","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:02:37.728583Z","iopub.execute_input":"2023-01-17T18:02:37.729338Z","iopub.status.idle":"2023-01-17T18:07:02.934929Z","shell.execute_reply.started":"2023-01-17T18:02:37.729292Z","shell.execute_reply":"2023-01-17T18:07:02.933963Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"2023-01-17 18:02:37.928581: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2023-01-17 18:02:40.378173: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"2024/2024 [==============================] - 265s 126ms/step - loss: 0.2119 - multi_label_acc: 0.9197 - fbeta: 0.7121 - val_loss: 0.1575 - val_multi_label_acc: 0.9368 - val_fbeta: 0.7702\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f38117b3710>"},"metadata":{}}]},{"cell_type":"code","source":"##adding .jpg extension to image name in the sample submission file\nsample_submission = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:07:02.936287Z","iopub.execute_input":"2023-01-17T18:07:02.937162Z","iopub.status.idle":"2023-01-17T18:07:03.069840Z","shell.execute_reply.started":"2023-01-17T18:07:02.937122Z","shell.execute_reply":"2023-01-17T18:07:03.068791Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   image_name                                  tags\n0  test_0.jpg  primary clear agriculture road water\n1  test_1.jpg  primary clear agriculture road water\n2  test_2.jpg  primary clear agriculture road water\n3  test_3.jpg  primary clear agriculture road water\n4  test_4.jpg  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"modelnew.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:07:03.071048Z","iopub.execute_input":"2023-01-17T18:07:03.071414Z","iopub.status.idle":"2023-01-17T18:07:03.137581Z","shell.execute_reply.started":"2023-01-17T18:07:03.071378Z","shell.execute_reply":"2023-01-17T18:07:03.136640Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#we divide the sample submission file into two splits, first test1_df which contains the first 40669 images \ntest1_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\ntest1_df.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:07:03.139271Z","iopub.execute_input":"2023-01-17T18:07:03.139688Z","iopub.status.idle":"2023-01-17T18:07:03.155431Z","shell.execute_reply.started":"2023-01-17T18:07:03.139648Z","shell.execute_reply":"2023-01-17T18:07:03.154394Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   image_name\n0  test_0.jpg\n1  test_1.jpg\n2  test_2.jpg\n3  test_3.jpg\n4  test_4.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#initializing imagedatagenerator for the test images and also rescaling\ntest_image_gen = ImageDataGenerator(rescale = 1/255)\n\n\n#creating a generator for the images found in the first test image files\ntest_generator1 = test_image_gen.flow_from_dataframe(dataframe=test1_df, \n                                                directory=\"../input/planets-dataset/planet/planet/test-jpg\", \n                                                x_col=\"image_name\", y_col=None, batch_size=16, \n                                                shuffle=False, class_mode=None, target_size=(128,128))\n\nstep_test_size1 = int(np.ceil(test_generator1.samples/test_generator1.batch_size))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:07:03.157163Z","iopub.execute_input":"2023-01-17T18:07:03.157575Z","iopub.status.idle":"2023-01-17T18:07:43.919116Z","shell.execute_reply.started":"2023-01-17T18:07:03.157536Z","shell.execute_reply":"2023-01-17T18:07:43.918061Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Found 40669 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#first, we reset the test generator to avoid shuffling of index as we want it to be orderly\ntest_generator1.reset()\npred1 = modelnew.predict(test_generator1, steps = step_test_size1, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:08:20.639714Z","iopub.execute_input":"2023-01-17T18:08:20.640145Z","iopub.status.idle":"2023-01-17T18:12:59.611767Z","shell.execute_reply.started":"2023-01-17T18:08:20.640110Z","shell.execute_reply":"2023-01-17T18:12:59.610778Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"2542/2542 [==============================] - 279s 110ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names1 = test_generator1.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5 \npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this \nresult1 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\nresult1.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:12:59.613873Z","iopub.execute_input":"2023-01-17T18:12:59.614704Z","iopub.status.idle":"2023-01-17T18:13:08.839914Z","shell.execute_reply.started":"2023-01-17T18:12:59.614663Z","shell.execute_reply":"2023-01-17T18:13:08.838776Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          primary clear\n1  test_1.jpg          primary clear\n2  test_2.jpg  primary partly_cloudy\n3  test_3.jpg          primary clear\n4  test_4.jpg  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#second batch of the test dataset\ntest2_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\ntest2_df.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:13:08.842267Z","iopub.execute_input":"2023-01-17T18:13:08.842947Z","iopub.status.idle":"2023-01-17T18:13:08.855527Z","shell.execute_reply.started":"2023-01-17T18:13:08.842908Z","shell.execute_reply":"2023-01-17T18:13:08.854242Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"      image_name\n0     file_0.jpg\n1     file_1.jpg\n2    file_10.jpg\n3   file_100.jpg\n4  file_1000.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#creating a generator for the second batch of test image files\ntest_generator2 = test_image_gen.flow_from_dataframe(dataframe=test2_df, \n                                                directory=\"../input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n                                                x_col=\"image_name\", y_col=None, batch_size=16, \n                                                shuffle=False, class_mode=None, target_size=(128,128))\n\nstep_test_size2 = int(np.ceil(test_generator2.samples/test_generator2.batch_size))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:13:08.858572Z","iopub.execute_input":"2023-01-17T18:13:08.858937Z","iopub.status.idle":"2023-01-17T18:13:41.381911Z","shell.execute_reply.started":"2023-01-17T18:13:08.858889Z","shell.execute_reply":"2023-01-17T18:13:41.380775Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Found 20522 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#we reset the generator to avoid shuffling, then make prediction on the generator\ntest_generator2.reset()\npred2 = modelnew.predict(test_generator2, steps = step_test_size2, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:13:41.383641Z","iopub.execute_input":"2023-01-17T18:13:41.384018Z","iopub.status.idle":"2023-01-17T18:16:02.055012Z","shell.execute_reply.started":"2023-01-17T18:13:41.383966Z","shell.execute_reply":"2023-01-17T18:16:02.054036Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"1283/1283 [==============================] - 141s 110ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names2 = test_generator2.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5\npred_tags2 = pd.DataFrame(pred2)\npred_tags2 = pred_tags2.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this\nresult2 = pd.DataFrame({'image_name': file_names2, 'tags': pred_tags2})\nresult2.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:16:02.056917Z","iopub.execute_input":"2023-01-17T18:16:02.057690Z","iopub.status.idle":"2023-01-17T18:16:06.795374Z","shell.execute_reply.started":"2023-01-17T18:16:02.057650Z","shell.execute_reply":"2023-01-17T18:16:06.794270Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"      image_name                         tags\n0     file_0.jpg                 primaryclear\n1     file_1.jpg  agricultureprimaryclearroad\n2    file_10.jpg                       cloudy\n3   file_100.jpg      agricultureprimaryclear\n4  file_1000.jpg                 primaryclear","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n      <td>primaryclear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n      <td>agricultureprimaryclearroad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n      <td>cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n      <td>agricultureprimaryclear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n      <td>primaryclear</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#for the final result of the predicted tags for the test images, we need to concat the first and second results in \n#that order to avoid shuffling the index\nlast_result = pd.concat([result1, result2])\n\nlast_result = last_result.reset_index().drop('index', axis =1)\n\nprint(last_result.shape)\n#print the final result\nlast_result.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:16:06.797026Z","iopub.execute_input":"2023-01-17T18:16:06.797395Z","iopub.status.idle":"2023-01-17T18:16:06.816203Z","shell.execute_reply.started":"2023-01-17T18:16:06.797358Z","shell.execute_reply":"2023-01-17T18:16:06.814966Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(61191, 2)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          primary clear\n1  test_1.jpg          primary clear\n2  test_2.jpg  primary partly_cloudy\n3  test_3.jpg          primary clear\n4  test_4.jpg  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#we need to remove the .jpg extension from the image_name of the last_result because from the sample submission the \n#extension was not there, we added it for easy manipulation of the data.\nlast_result['image_name'] = last_result['image_name'].apply(lambda x: x[:-4])\nlast_result.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-01-17T18:16:06.818041Z","iopub.execute_input":"2023-01-17T18:16:06.818525Z","iopub.status.idle":"2023-01-17T18:16:06.846138Z","shell.execute_reply.started":"2023-01-17T18:16:06.818485Z","shell.execute_reply":"2023-01-17T18:16:06.845115Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"  image_name                   tags\n0     test_0          primary clear\n1     test_1          primary clear\n2     test_2  primary partly_cloudy\n3     test_3          primary clear\n4     test_4  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"last_result.to_csv('submissionfinal.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:16:06.847602Z","iopub.execute_input":"2023-01-17T18:16:06.847967Z","iopub.status.idle":"2023-01-17T18:16:06.927047Z","shell.execute_reply.started":"2023-01-17T18:16:06.847929Z","shell.execute_reply":"2023-01-17T18:16:06.926174Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}